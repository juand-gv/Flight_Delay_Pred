{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Predicting flight delays using PySpark\n",
    "\n",
    "In this Notebook we will predict flight delays using PySpark. We will use to basic machine learning models namely Decision Tree and Logistic Regression to achieve this task.\n",
    "\n",
    "This notebook is based on [RASHID60's notebook](https://www.kaggle.com/code/rashid60/ml-with-pyspark-predicting-flight-delays) and is used just for learning purposes.\n",
    "\n",
    "## Input Data\n",
    "\n",
    "Data columns:\n",
    "- mon — month (int between 1 and 12)\n",
    "- dom — day of month (int between 1 and 31)\n",
    "- dow — day of week (int; 1 = Monday and 7 = Sunday)\n",
    "- org — origin airport (str; IATA code)\n",
    "- mile — distance (int; miles)\n",
    "- carrier — carrier (str; IATA code)\n",
    "- depart — departure time (int; decimal hour)\n",
    "- duration — expected duration (int; minutes)\n",
    "- delay — delay (int; minutes)\n",
    "- (IATA -> International Air Transport Association)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importing packages and libs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "from pyspark.sql.functions import round\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.2\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "                    .master('local[*]') \\\n",
    "                    .appName('FlightDelayPred') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "# Get Spark Version\n",
    "print(spark.version)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Exploration"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "flights_df = spark.read.csv(\n",
    "                            \"flights-larger.csv\",\n",
    "                            sep=\",\",\n",
    "                            header=True,\n",
    "                            inferSchema=True,\n",
    "                            nullValue=\"NA\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contains 275000 records.\n"
     ]
    }
   ],
   "source": [
    "# Get amount of records\n",
    "print(f\"The data contains {flights_df.count()} records.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "| 10| 10|  1|     OO|  5836|ORD| 157|  8.18|      51|   27|\n",
      "|  1|  4|  1|     OO|  5866|ORD| 466|  15.5|     102| null|\n",
      "| 11| 22|  1|     OO|  6016|ORD| 738|  7.17|     127|  -19|\n",
      "|  2| 14|  5|     B6|   199|JFK|2248| 21.17|     365|   60|\n",
      "|  5| 25|  3|     WN|  1675|SJC| 386| 12.92|      85|   22|\n",
      "|  3| 28|  1|     B6|   377|LGA|1076| 13.33|     182|   70|\n",
      "|  5| 28|  6|     B6|   904|ORD| 740|  9.58|     130|   47|\n",
      "|  1| 19|  2|     UA|   820|SFO| 679| 12.75|     123|  135|\n",
      "|  8|  5|  5|     US|  2175|LGA| 214|  13.0|      71|  -10|\n",
      "|  5| 27|  5|     AA|  1240|ORD|1197| 14.42|     195|  -11|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check first 10 rows\n",
    "flights_df.show(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mon', 'int'), ('dom', 'int'), ('dow', 'int'), ('carrier', 'string'), ('flight', 'int'), ('org', 'string'), ('mile', 'int'), ('depart', 'double'), ('duration', 'int'), ('delay', 'int')]\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(flights_df.dtypes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preparation\n",
    "\n",
    "**Data Cleaning**\n",
    "- Removing uninformative column\n",
    "- Removing rows with missing values\n",
    "\n",
    "**Column/Data manipulation**\n",
    "- A flight is considered \"delayed\" when it arrives more than 15 minutes after its scheduled time\n",
    "- Creation of new boolean column \"label\" stating if a flight was delayed or not\n",
    "- Convert columns that hold categorical data into indexed numerical values\n",
    "\n",
    "**Assembling columns**\n",
    "- Consolidate all predictor columns into a single one"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contains now 258289 records.\n"
     ]
    }
   ],
   "source": [
    "# Removing \"flight\" column\n",
    "flights_drop_flight_df = flights_df.drop(\"flight\")\n",
    "\n",
    "# Removing records with missing \"delay\" values\n",
    "flights_valid_delay_df = flights_drop_flight_df.filter(\"delay IS NOT NULL\")\n",
    "\n",
    "# Remove records with missing values\n",
    "flights_no_missing_df = flights_valid_delay_df.dropna()\n",
    "print(f\"The data contains now {flights_no_missing_df.count()} records.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Converting column \"mile\" to \"km\" and dropping it afterwards\n",
    "flights_km_df = flights_no_missing_df.withColumn(\"km\", round(flights_no_missing_df.mile * 1.609, 0)) \\\n",
    "                                .drop(\"mile\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "| 10| 10|  1|     OO|ORD|  8.18|      51|   27| 253.0|    1|\n",
      "| 11| 22|  1|     OO|ORD|  7.17|     127|  -19|1187.0|    0|\n",
      "|  2| 14|  5|     B6|JFK| 21.17|     365|   60|3617.0|    1|\n",
      "|  5| 25|  3|     WN|SJC| 12.92|      85|   22| 621.0|    1|\n",
      "|  3| 28|  1|     B6|LGA| 13.33|     182|   70|1731.0|    1|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating \"label\" column for identifying whether a flight is delayed or not\n",
    "flights_label_df = flights_km_df.withColumn(\"label\", (flights_km_df.delay >= 15).cast(\"integer\"))\n",
    "\n",
    "# Show first 5 records to check the result\n",
    "flights_label_df.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check [StringIndexer](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.StringIndexer.html#stringindexer) in Spark docs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Create an indexer, which identifies categories and then creates a new column\n",
    "# with numeric index values\n",
    "flights_indexed_df = StringIndexer(inputCol=\"carrier\", outputCol=\"carrier_idx\") \\\n",
    "                                    .fit(flights_label_df) \\\n",
    "                                    .transform(flights_label_df)\n",
    "# Repeating the process for org column\n",
    "flights_indexed_df = StringIndexer(inputCol=\"org\", outputCol=\"org_idx\") \\\n",
    "                                    .fit(flights_indexed_df) \\\n",
    "                                    .transform(flights_indexed_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|carrier_idx|org_idx|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
      "| 10| 10|  1|     OO|ORD|  8.18|      51|   27| 253.0|    1|        2.0|    0.0|\n",
      "| 11| 22|  1|     OO|ORD|  7.17|     127|  -19|1187.0|    0|        2.0|    0.0|\n",
      "|  2| 14|  5|     B6|JFK| 21.17|     365|   60|3617.0|    1|        4.0|    2.0|\n",
      "|  5| 25|  3|     WN|SJC| 12.92|      85|   22| 621.0|    1|        3.0|    5.0|\n",
      "|  3| 28|  1|     B6|LGA| 13.33|     182|   70|1731.0|    1|        4.0|    3.0|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_indexed_df.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check [VectorAssembler](https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.ml.feature.VectorAssembler.html) in Spark docs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+-----+\n",
      "|features                                 |delay|\n",
      "+-----------------------------------------+-----+\n",
      "|[10.0,10.0,1.0,2.0,0.0,253.0,8.18,51.0]  |27   |\n",
      "|[11.0,22.0,1.0,2.0,0.0,1187.0,7.17,127.0]|-19  |\n",
      "|[2.0,14.0,5.0,4.0,2.0,3617.0,21.17,365.0]|60   |\n",
      "|[5.0,25.0,3.0,3.0,5.0,621.0,12.92,85.0]  |22   |\n",
      "|[3.0,28.0,1.0,4.0,3.0,1731.0,13.33,182.0]|70   |\n",
      "+-----------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating an assembler object\n",
    "assembler_cols = ['mon', 'dom', 'dow', 'carrier_idx', 'org_idx', 'km', 'depart', 'duration']\n",
    "assembler = VectorAssembler(inputCols=assembler_cols, outputCol=\"features\")\n",
    "\n",
    "# Consolidate predictor columns\n",
    "flights_assembled_df = assembler.transform(flights_indexed_df)\n",
    "\n",
    "# Checking the resulting column\n",
    "flights_assembled_df.select(\"features\", \"delay\").show(5, truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ML Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1) Decition Trees\n",
    "\n",
    "Offers inherit simplicity and explainability"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ratio: 0.799352663102184\n",
      "Testing ratio: 0.20064733689781603\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing sets with 80-20 ratio\n",
    "flights_train, flights_test = flights_assembled_df.randomSplit([0.8, 0.2], seed=2022)\n",
    "\n",
    "# Check amount of records\n",
    "training_ration = flights_train.count()/flights_assembled_df.count()\n",
    "testing_ration = flights_test.count()/flights_assembled_df.count()\n",
    "\n",
    "print(f\"Training ratio: {training_ration}\\nTesting ratio: {testing_ration}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------------------------------------+\n",
      "|label|prediction|probability                             |\n",
      "+-----+----------+----------------------------------------+\n",
      "|0    |1.0       |[0.3587724540373326,0.6412275459626674] |\n",
      "|1    |0.0       |[0.6453918288098484,0.3546081711901516] |\n",
      "|0    |1.0       |[0.44187343183718986,0.5581265681628101]|\n",
      "|0    |1.0       |[0.3587724540373326,0.6412275459626674] |\n",
      "|0    |1.0       |[0.3587724540373326,0.6412275459626674] |\n",
      "+-----+----------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a Decision Tree classifier object and fit the training data\n",
    "tree = DecisionTreeClassifier()\n",
    "tree_model = tree.fit(flights_train)\n",
    "\n",
    "# Creating predictions on test data\n",
    "tree_prediction = tree_model.transform(flights_test)\n",
    "tree_prediction.select(\"label\", \"prediction\", \"probability\").show(5, truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Evaluate the model**\n",
    "\n",
    "A confusion matrix gives a useful breakdown of predictions versus known values. It has four cells which represent the counts of:\n",
    "- True Negatives (TN) — prediction is negative & label is negative\n",
    "- True Positives (TP) — prediction is positive & label is positive\n",
    "- False Negatives (FN) — prediction is negative & label is positive\n",
    "- False Positives (FP) — prediction is positive & label is negative\n",
    "\n",
    "Using these four measure, we can then calculate the accuracy of the model as follows:\n",
    "\n",
    "Accuracy=(TN+TP)/(TN+TP+FN+FP)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 8800|\n",
      "|    0|       0.0|15215|\n",
      "|    1|       1.0|17517|\n",
      "|    0|       1.0|10293|\n",
      "+-----+----------+-----+\n",
      "\n",
      "Accuracy: 0.6315870718765074\n"
     ]
    }
   ],
   "source": [
    "# Creating confusion matrix\n",
    "tree_prediction.groupBy(\"label\", \"prediction\").count().show()\n",
    "\n",
    "# Calculating the elements of the confusion matrix\n",
    "tree_TN = tree_prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "tree_TP = tree_prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "tree_FN = tree_prediction.filter('prediction = 0 AND label != prediction').count()\n",
    "tree_FP = tree_prediction.filter('prediction = 1 AND label != prediction').count()\n",
    "\n",
    "# Accuracy measures the proportion of correct predictions\n",
    "tree_accuracy = (tree_TN + tree_TP) / (tree_TN + tree_TP + tree_FN + tree_FP)\n",
    "print(f\"Accuracy: {tree_accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The accuracy is decent but not a good one. We have a lot of false predictions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression:\n",
    "\n",
    "Simple and easy to train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 9747|\n",
      "|    0|       0.0|14753|\n",
      "|    1|       1.0|16570|\n",
      "|    0|       1.0|10755|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a classifier object and train on training data\n",
    "logistic = LogisticRegression().fit(flights_train)\n",
    "\n",
    "# Creating predictions for the testing data and show confusion matrix\n",
    "logistic_prediction = logistic.transform(flights_test)\n",
    "logistic_prediction.groupBy(\"label\", \"prediction\").count().show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.63\n",
      "recall    = 0.67\n"
     ]
    }
   ],
   "source": [
    "# Calculating the elements of the confusion matrix\n",
    "logistic_TN = tree_prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "logistic_TP = tree_prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "logistic_FN = tree_prediction.filter('prediction = 0 AND label != prediction').count()\n",
    "logistic_FP = tree_prediction.filter('prediction = 1 AND label != prediction').count()\n",
    "\n",
    "# Calculate precision and recall\n",
    "logistic_precision = logistic_TP / (logistic_TP + logistic_FP)\n",
    "logistic_recall = logistic_TP / (logistic_TP + logistic_FN)\n",
    "print('precision = {:.2f}\\nrecall    = {:.2f}'.format(logistic_precision, logistic_recall))\n",
    "\n",
    "# Find weighted precision\n",
    "multi_evaluator = MulticlassClassificationEvaluator()\n",
    "weighted_precision = multi_evaluator.evaluate(logistic_prediction,\n",
    "                                              {multi_evaluator.metricName: \"weightedPrecision\"})\n",
    "\n",
    "# Find AUC\n",
    "binary_evaluator = BinaryClassificationEvaluator()\n",
    "auc = binary_evaluator.evaluate(logistic_prediction, {binary_evaluator.metricName: \"areaUnderROC\"})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Again the matrices are reflecting decent values but not good ones.\n",
    "Which means, improving in models' efficiency can be considered as potential future work."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "#Close spark session\n",
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}